{
  "hash": "3ba41550b7d3f957c8bb4a19e9c0e1d2",
  "result": {
    "markdown": "---\ntitle: Linear model extensions\nsubtitle: How to fix it when it's broken\nbibliography: ../references.bib\n---\n\n\n<!-- COMMENT NOT SHOW IN ANY OUTPUT: Code chunk below sets overall defaults for .qmd file; these inlcude showing output by default and looking for files relative to .Rpoj file, not .qmd file, which makes putting filesin different folders easier  -->\n\n\n\n\n\nThe past several chapters/lessons have focused on linear models. Here we\nexplore options for analysis when linear model assumptions are not met.\nIn doing so, we review several different approaches, many of which could\nbe (and are) the focal topic of courses and books. The goal here is to\n\n-   help you figure out when you may need to employ these methods by\n    having you understand what they do/fix\n\n-   give you a start on doing these analyses in R\n\nCitations to relevant articles papers and books are noted throughout for\nfurther exploration.\n\n## Sticking with the linear model\n\nLinear models are useful for a number of reasons. They are a great way\nto unify most/many tests from classical statistics. In fact, most of the\nranked tests we've developed can actually be run as linear models when n\n\\>15. For example, we can go back to our Wilcox-Mann Whitney U tests\n(for 2 populations) and Kruskal-Wallis (for 3+) from the [comparing\nmeans among groups\nchapter](Compare_means_among_populations.qmd){target=\"_blank\"} and note\nthe outcome from a *wilcox.test*\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntwo_species_subset <- iris[iris$Species!=\"setosa\",]\nwilcox.test(Sepal.Length ~ Species, two_species_subset)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWilcoxon rank sum test with continuity correction\n\ndata:  Sepal.Length by Species\nW = 526, p-value = 5.869e-07\nalternative hypothesis: true location shift is not equal to 0\n```\n:::\n:::\n\n\nis very close to a linear model predicting the signed rank of the data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(car)\nsigned_rank = function(x) sign(x) * rank(abs(x))\nAnova(lm(signed_rank(Sepal.Length) ~ Species, two_species_subset), type=\"III\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnova Table (Type III tests)\n\nResponse: signed_rank(Sepal.Length)\n            Sum Sq Df F value    Pr(>F)    \n(Intercept)  64872  1 102.378 < 2.2e-16 ***\nSpecies      20967  1  33.089 1.003e-07 ***\nResiduals    62098 98                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nIn fact, we could run simulations and show that p values from these 2\napproaches are highly correlated (now you know what that means) with a\n$\\beta$ of almost 1 (from @lindelov).\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Linear_model_extensions_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nLinear models are also extremely robust. Consider the basic assumptions\nof a linear model\n\n$$\n\\epsilon \\approx i.i.d.\\ N(\\mu,\\sigma)\n$$\n\nAlthough the residuals are meant to be homoscedastic (equal or constant\nacross all groups), it turns out the model is robust of when the largest\ngroup variance is 4-10x larger than the smallest group variance and\nsample sizes are approximately equal [@blanca2018; @fox2015; @zuur2010],\nthough highly uneven group sizes begin to cause issues [@blanca2018].\n\nSimilarly, non-normal data is not an issue. This is partially because\nthe assumptions are focused on residuals, but also because the procedure\nis highly robust [@blanca2017]. This finding further supports the\ngraphical consideration of assumptions , especially since many tests for\nnormality are conservative (samples are almost never *perfectly* normal,\nand slight deviations are easier to pick up with larger sample sizes\ndespite the fact the central limit theorem suggests this is when the\nissue is least important) [@zuur2010; @shatz2023].\n\nThese issues have led some authors to argue violations of the linear\nmodel assumptions are less dangerous than trying new, and often\nless-tested, techniques that may inflate type I error rates [@knief2021;\n@warton2016]. However, new techniques (or sometimes old techniques that\nare new to a given field) may be more appropriate when assumptions are\nclearly broken [@warton2010; @reitan2016; @geissinger2022]. In this\nsection we explore common-ish approaches for analyzing data when the\nassumptions of a linear model are broken. Our goal here is to introduce\nthese methods. Each could be the focus of their own class, book, or much\nlarger study. Fortunately most can be viewed as extensions to our\nexisting knowledge, although many of the assumptions and techniques for\nthem are less developed/still being argued about.\n\nThe various assumptions related to linear models may be prioritized on\ntheir relative importance. One such order is provided (roughly) by\n@gelman2006.\n\n-   Model validity\n\n    -   As noted in the multiple regression chapter, we only should\n        investigate relationships we have a mechanism to explain\n\n-   Linear relationship and additive effects of predictor variables\n\n-   Errors are\n\n    -   independently distributed\n\n    -   identical (homoscedastic)\n\n    -   follow a normal distribution\n\nMany datasets will violate multiple of these assumptions simultaneously,\nso addressing issues is often best resolved by understanding *why* this\nis happening.\n\n## Linear relationship is inappropriate\n\nA central (and often overlooked assumption) of linear models is that the\nrelationship between the predictors and the outcome variable is linear\nand addtive. When the relationship is not linear, the resulting\nresiduals are often not appropriately distributed as well.\n\n<details>\n\n<summary>What's linear anyway?</summary>\n\nTo be clear, the linear model only focuses on the linear and additive\nrelationship between the predictors and the outcome variable (this will\nbecome more important/obvious later in this section!). The model doesn't\n*know* what the variables are. For that reason, we can add predictor\nvariables to a model that are squares or cubes of predictors, or we can\ntransform the outcome variable. We just need the $Y = X\\beta$\nrelationship to be additive and linear.\n\n</details>\n\nWhen non-linearity occurs, several options to address it exist. The best\napproach may depend on why the relationship is non-linear, as\nrelationships among variables may be non-linear for a number of reasons.\nFor example, the outcome may not actually be continuous (e.g. counts.\nproportions), and thus true linear relationships are not possible;\noutcomes may also be related to the predictors in different ways (e.g.,\nlogarithmic).\n\n### Transform the data (least advisable, sometimes)\n\nOne way to address non-linearity is to transform the data (typically\nfocusing on the dependent variable) so that the resulting variable meets\nthe linear model assumptions (and thus uses the strengths of linear\nmodels that we noted above). As shown above, our rank-based approaches\nare using a similar method (not technically the same, but it works for\nlarger sample sizes). This approach was often used in the past (e.g.,\narc-sin transforms of proportion data @warton2010) and supported by\nvarious approaches. For example, the Box-Cox transformation helped\nresearchers find the best way to transform data to reduce issues with\nthe distribution of residuals; this method also tended to impact\nlinearity and differences in variances.\n\nTwo things should be noted regarding this approach and transformations\nin general:\n\n-   The Box-Cox approach requires a model - it still focused on\n    transforming data so that *residuals* meet assumptions. Data should\n    not be transformed before model assumptions are analyzed to ensure\n    it is necessary. For example, highly skewed data may arise due to\n    unequal sample sizes (which may pose their own problems, but not\n    outright), but models using this data may meet assumptions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(8)\nexample_skewed <- data.frame(Population= c(rep(\"a\",40),\n                                           rep(\"b\", 30),\n                                           rep(letters[3:4], each=15)), \n                             Growth = c(rnorm(40,1),\n                                    rnorm(30, 4),\n                                    rnorm(15, 7),\n                                    rnorm(15,10)))\nlibrary(ggplot2)\nggplot(example_skewed,aes(x=Growth))+\n  geom_histogram()+\n  labs(y=\"Some value\",\n       title=\"Example of skewed data appearing due to unequal sample size\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](Linear_model_extensions_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(lm(Growth~Population, example_skewed))\n```\n\n::: {.cell-output-display}\n![](Linear_model_extensions_files/figure-html/unnamed-chunk-4-2.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](Linear_model_extensions_files/figure-html/unnamed-chunk-4-3.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](Linear_model_extensions_files/figure-html/unnamed-chunk-4-4.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](Linear_model_extensions_files/figure-html/unnamed-chunk-4-5.png){width=672}\n:::\n\n```{.r .cell-code}\nAnova(lm(Growth~Population, example_skewed), type=\"III\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnova Table (Type III tests)\n\nResponse: Growth\n             Sum Sq Df F value    Pr(>F)    \n(Intercept)   38.75  1  32.436 1.344e-07 ***\nPopulation  1007.71  3 281.175 < 2.2e-16 ***\nResiduals    114.69 96                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n-   Similary (and already noted!). non-normal data may lead to models\n    with normal residuals. However, normal data (or data transformed to\n    be *more* normal) does typically lead to normal residuals, so if\n    residuals are not normal transformations may help.\n\n-   The transformed variable is *now* linear in respect to the\n    predictors. This highlights the actual assumption of the model.\n    Similarly, higher-terms (squares, cubes, etc) may be added to a\n    linear model. The model does not care what the data represent - it\n    only focuses on if linear relationships exist among them.\n\n-   Transformations can make model interpretation and prediction\n    difficult.\n\nIf the decision is made to transform the data, several approaches exist.\nSome are driven by the distribution of the data, and all depend on it.\nFor example, log and related root transformations are useful for\nright-skewed data, but some can only be carried out for non-negative\n(e.g., square root) or strictly positive (e.g., log) values. To address\nthis for log transformations, a small value is often added to 0\nmeasurements.\n\nLet's use data (not residuals) to show what different types of data look\nlike and consider possible fixes (always fit a model first for real\nanalysis!). For example, we can return to our right-skewed blue jay data\n[from the summarizing data\nchapter](summarizing_data.qmd)(target=\"\\_blank\")(idea from [@hunt]) .\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(19)\nblue_jays <- round(rbeta(10000,2,8)*100+runif(10000,60,80),3)\nggplot(data.frame(blue_jays), \n       aes(x=blue_jays)) +\n  geom_histogram( fill=\"blue\", color=\"black\") +\n  labs(title=\"Weight of Westchester blue jays\",\n       x= \"Weight (g)\",\n       y= \"Frequency\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](Linear_model_extensions_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nNote the right-skewed data shows a convex curve on the Q-Q plot.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqqnorm(blue_jays)\nqqline(blue_jays)\n```\n\n::: {.cell-output-display}\n![](Linear_model_extensions_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\nTo help you understand Q-Q plots, remember they are comparing the\nrelative spread of data (quantiles) from a target and theoretical\ndistribution. For right-skewed data, points are shifted right (both\nsmallest and largest observations are larger than you would expect from\na normal distribution).\n\nConversely, we could also return to our left-skewed cardinal data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(19)\ncardinals <- round(rbeta(10000,10,2)*50+runif(10000,5,10),3)\nggplot(data.frame(cardinals), \n       aes(x=cardinals)) +\n  geom_histogram( fill=\"red\", color=\"black\") +\n  labs(title=\"Weight of Westchester cardinals\",\n       x= \"Weight (g)\",\n       y= \"Frequency\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](Linear_model_extensions_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nand note a concave shape is seen in the Q-Q plot,as all points are\nshifted left.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqqnorm(cardinals)\nqqline(cardinals)\n```\n\n::: {.cell-output-display}\n![](Linear_model_extensions_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nFor this type of data, power transformations (raising the variable to\nthe 2, 3, or higher power) may be useful.\n\nMeanwhile, our uniformly-distributed distributed robin data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(19)\nrochester <- round(c(runif(1000,75,85)),3)\nggplot(data.frame(rochester), \n       aes(x=rochester)) +\n  geom_histogram( fill=\"pink\", color=\"black\") +\n  labs(title=\"Weight of Rochester robins\",\n       x= \"Weight (g)\",\n       y= \"Frequency\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](Linear_model_extensions_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\nshows as a s-shape on the Q-Q plot\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqqnorm(rochester)\nqqline(rochester)\n```\n\n::: {.cell-output-display}\n![](Linear_model_extensions_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\nbecause it is *under-dispersed* (has no tails, and thus the lower points\nare larger than expected and the higher points are smaller than\nexpected). Alternatively, data may be *over-dispersed*, like this (fake)\nfinch data where lower points are lower than expected and higher points\nare higher.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(19)\nlibrary(VGAM)\nfinch <- rlaplace(1000,location=50, scale=4)\nggplot(data.frame(finch), \n       aes(x=finch)) +\n  geom_histogram( fill=\"cyan\", color=\"black\") +\n  labs(title=\"Weight of finches\",\n       x= \"Weight (g)\",\n       y= \"Frequency\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](Linear_model_extensions_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nqqnorm(finch)\nqqline(finch)\n```\n\n::: {.cell-output-display}\n![](Linear_model_extensions_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\nOver- and under-dispersed data may mean there's a missing factor in your\nanalysis. For example, our bi-modal woodpecker data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(19)\nwoodpeckers <- round(c(rnorm(100,60,4),rnorm(100,80,4)),3)\nggplot(data.frame(woodpeckers), \n       aes(x=woodpeckers)) +\n  geom_histogram( fill=\"orange\", color=\"black\") +\n  labs(title=\"Weight of  Westchester woodpeckers\",\n       x= \"Weight (g)\",\n       y= \"Frequency\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](Linear_model_extensions_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\nis under-dispersed due the shape of the distribution, but there also\nsigns of other issues.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqqnorm(woodpeckers)\nqqline(woodpeckers)\n```\n\n::: {.cell-output-display}\n![](Linear_model_extensions_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\nUnder-dispersion could also happen if data are bounded (e.g., by\npracticality or due to a measurement issue). Over-dispersion can\nsimilarly occur if the model does not account for variability (e.g.,\nmissing factors, non-linear relationship) and/or outliers, which might\nbe related to the underlying form of the data [@payne2017] (more to come\non this). In this way, over- and under-dispersion relate to both the\nlinear relationship.\n\n### Different data require a different approach: Introducing generalized linear models\n\nThe linear relationship may be inappropriate because our data doesn't\nfit it! For example, if we are modeling proportions, estimates less than\n0 or below 1 do not make sense, but a linear model doesn't account for\nthat. The same issues arise for binary outcomes (outcome must be 0 or 1)\nand count data (where outcomes can't be non-integer). While we may be\nable to transform the response variable to make relationships linear,\nanother option is to translate the *link* function.\n\nAlthough we haven't fully explained it yet, a linear model contains\nthree components. There is always a random component that focuses on the\ndistribution of the data. There is also a systematic component, where a\nnumber of covariates and data points produce an estimate. Finally, there\nis the link function, which connects that estimate to the data\ndistribution (this maintains the linearity of the model).\n\nNotice this means the link connects to the distribution of the data, not\nthe data itself (which is what transforming the data is doing). So far\nwe have focused on the *mean* of the data, and the estimate is the mean,\nso the link has been implied. We can *generalize* this setup to include\nother distributions in the exponential family (and now others\n[@applied2022, ch. 15]).\n\nWhile we won't develop all the math, exponential family distributions\nall have a canonical parameter (the mean for Gaussian, or normal, data)\nand a dispersion parameter (the variance for normal data). Different\ndistributions have different relationships between these two parameters.\nFor normal data, there is *no* relationship, so the variance is\nconstant. This is not true for other families; for example, the variance\nin binomial data depends on the *p* parameter (as we noted in the\n\\[chapter introducing binomial data\\](Binomial.qmd){target=\"\\_blank\"))!\n\nWe can specify other families using *generalized linear models* (which\nare different than general linear models, which is another term used to\ndescribe our \"regular\" linear models). These models are also known as\nglm or glim (we'll use the glm jargon here). GLM make different\nassumptions (though everyone does not agree on what they are!). While we\nstill need independence of the residuals (or some extension, see below),\nthey no longer need to be normally distributed [@zuur2007, p. 86-87;\n@zuur2009, section 9.8.3] (though normality may hold at large sample\nsizes for Pearson [@agresti2007, p. 87] or deviance [@montgomery2012,\nsection 13.4.4]\n<!-- https://stats.stackexchange.com/questions/92394/checking-residuals-for-normality-in-generalised-linear-models; https://online.stat.psu.edu/stat504/lesson/6/6.1 -->\nresiduals, and some authors argue normality is required for testing\n[@feng2020]) . As noted above, non-Gaussian families don't assume a\nconstant variance, so homogeneity assumptions would not be appropriate\n[@fox2016]. However, we need to ensure the correct family (and thus\nmean-variance link) is chosen. In general, plotting the residuals\nagainst [@zuur2009]\n\n-   the predicted values\n\n    -   to check for model fit\n\n-   each explanatory variable in model\n\n    -   to check for linearity\n\n-   each explanatory not retained/used in model\n\n    -   to check for missing patterns\n\n-   against time and space (if applicable)\n\n    -   to check for patterns and correlation\n\nwill be useful. Any patterns may suggest missing predictors or lack of\nindependence/correlation among measurements. Patterns in the residuals\nmay also indicate the incorrect family has been chosen [@zuur2009,\nsection 9.8.4]; for families with fixed dispersion parameters,\ninspection of the estimated dispersion parameter can also be a related\ndiagnostic.\n\n<details>\n\n<summary>What are residuals for a GLM?</summary>\n\nResiduals for a Gaussian/normal glm (what we've been doing) are easy to\ncalculate. We simply subtract the estimate for each data point (which is\nthe average for similar observations!) from the observed. However,\nthough these *raw* or *response* residuals exist for GLM, they rarely\nmake sense. Variance may increase with mean for some distributions, for\nexample, or outcomes may be binary (so every residual is 0 or 1!).\n\nTo account for this, we could divide the residuals by the standard\ndeviation of the observations. This normalizes the residuals and leads\nto *Pearson residuals*. Another option is based on something called\ndeviance. Deviance is similar to sums of squares but based on likelihood\n(which we shortly see is what we use to test for significance in GLM);\nit can also be considered the generalized form of variance or residual\nsums of squares. It is calculated as the difference of log-likelihoods\nbetween the focal model and the saturated model (or a model that has a\ncoefficient for every observation and thus will have perfect fit).\nDeviance residuals consider how important each point is to the overall\ndeviance. You can also compare the deviance of a model to a perfect fit\n(no deviance/saturated) model and an intercept-only model (worst fit,\nD~O~) and generate a pseudo-R^2^ measure using the formula\n\n$$\n1-\\frac{D}{D_O}\n$$\n\nThis is known as McFadden's pseudo-R^2^ value.\n\n</details>\n\nOnce developed, GLMs can use most of the tools we developed for basic\nlinear models. However, a few key differences exist. Estimation of\nparameters and significance for these models rely on maximum-likelihood\nmethods (remember, the ratio of likelihood values follow a $\\chi^2$\ndistribution and can thus provide a p-value to compare possible models\nas noted in [introducing G\ntests](Compare_proportions_among_populations.qmd){target=\"\\_blank\")).This\nmay be represented as a Z test for single parameters (since a $\\chi^2$\ndistribution is a Z distribution squared - sometimes labelled a Wald\ntest/statistic). F test reappear for distributions where we estimate the\ndispersion parameter (like the normal), but otherwise we can use the\ndispersion parameter to check that the right approach was taken.\n\nIt should be noted that solving for coefficents also requires iterative\napproaches due to non-linearity; common methods (not described here)\ninclude the Newton-Raphson or Fisher scoring methods. The key point here\nfor practice is any noted issues with optimization are due to this\nprocess. Finally, it should be noted that coefficients and predictions\nare related to the estimate, which is **no longer** the actual mean.\nThis means impacts and outcomes will need to be transformed (based on\nthe link) to the actual scale.\n\nThere are numerous types of GLMs. Here we outline some of the more\ncommon ones. Each of these deserves a much fuller treatment - remember,\nthe intent here is to get you to a place to where you can begin working\nwith them. @harrison2018 (which also covers mixed models (coming up!))\nprovides an excellent review of these models, and fuller treatments are\nprovided by @zuur2009 (chapters 8-11) and @fox2016 (chapters 14 - 15).\nFor each I provide the most relevant math, an example (or two), and some\nimmediate extensions.\n\n#### Logistic regression: Bernoulli and binomial outcomes\n\nLogistic regression focuses on modelling yes/no or success/failure\noutcomes (Bernoulli or binomial data) using the *logit* link (thus\nlogistic regression). The easy-to-understand issue here is that we want\nto focus on probability ($\\pi$), but that can only vary from 0 to 1.\nLinear models are thus inappropriate, but the logit link can be used\nwhere the systematic component of the model predicts\n\n$$\nlogit(\\pi) = \\ln(\\frac{\\pi}{1-\\pi}), \\text{where } \\pi \\text{ is the probability for a given set of outcomes}\n$$\n\nThis logit link is useful as it effectively connects the systematic\ncomponent and real data (the purpose of the link). This link also allows\ncoefficients to be interpreted as odds and odds ratios (introduced in\nthe [comparing proportions among\ngroups](Compare_proportions_among_populations.qmd)- we'll continue to\nsee connections this chapter for logistic regression). Remember, the\nodds can be written as\n\n$$\n\\frac{\\pi}{1-\\pi}\n$$\n\nFor a given coefficient $\\beta$, the logit link also means we can say a\n1 unit increase in that single variable leads to a change in the odds\nratio of $e^{\\beta}$. This also means no impact is shown as $\\beta = 0$,\nwith positive and negative numbers implying increases or decreases in\nodds, which is convenient. Other link options (not discussed here)\ninclude the probit and complementary log-log approaches. For a final\npiece of math, note the dispersion parameter for binomial data is not\nestimated - it is assumed to be 1.\n\nFor example, @blais2023 investigated how various factors impacted\nbehavior in garter snakes (*Thamnophis cyrtopsis*).\n\n[![Juan Carlos Fonseca Mata, CC BY-SA 4.0\n\\<https://creativecommons.org/licenses/by-sa/4.0\\>, via Wikimedia\nCommons](/images/Thamnophis_cyrtopsis_(Natricidae).jpg){fig-alt=\"Thamnophis cyrtopsis (Family: Natricidae). Common name: blackneck garter snake.\"}](https://https://commons.wikimedia.org/wiki/File:Thamnophis_cyrtopsis_(Natricidae).jpg)\n\nOne of their analyses considered how snake movement(labelled 0 for no\nmovement, 1 for movement) differed among age classes (adults and\njuveniles).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbehavior <- read.csv(\"data/database_Thamnophis_crytopsis_study - Copy of THCY_MH_BEH.csv\",\n                     stringsAsFactors = T)\nbehavior_table <- table(behavior$movement, behavior$ageclass)\nbehavior_table\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   \n    adult juvenile\n  0    29       29\n  1    14       16\n```\n:::\n:::\n\n\nYou may recognize this analyses could be carried out using $\\chi^2$\ntests.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchisq.test(behavior_table)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPearson's Chi-squared test with Yates' continuity correction\n\ndata:  behavior_table\nX-squared = 0.0051228, df = 1, p-value = 0.9429\n```\n:::\n:::\n\n\nwhich indicate no impact of age class on movement (p=.9429). You\n(hopefully) also remember we mentioned the Yate's correction (noted in\nthe output) was due to using a continuous distribution to fit counts. If\nwe remove it,\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchisq.test(behavior_table, correct = F)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPearson's Chi-squared test\n\ndata:  behavior_table\nX-squared = 0.087924, df = 1, p-value = 0.7668\n```\n:::\n:::\n\n\nwe find an answer that we can replicate using glm (since the outcome is\na 0 or 1 here!). We do this using the *glm* function in base R, which is\nvery similar to the *lm* function; the only difference is we now note\nthe distribution we are exploring using the \"family\" argument. Note\nBernoulli data is considered a subset of binomial data and thus\nclassified as \"binomial\".\n\n\n::: {.cell}\n\n```{.r .cell-code}\nas_glm <- glm(movement~ageclass, behavior, family = \"binomial\")\n```\n:::\n\n\nWe can then use our normal approach (including *summary*, *Anova*, and\n*glht* functions) to consider the outcomes. Checking assumptions is a\nlittle trickier than for linear models (as noted above). One major check\nis typically ensuring the dispersion parameter is correct. We can\ntypically check the parameter by dividing the residual deviance by its\nassociated degrees of freedom; this information is provided by the\n*summary* function (here, 112.84/86);\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(as_glm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = movement ~ ageclass, family = \"binomial\", data = behavior)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-0.9374  -0.9374  -0.8876   1.4381   1.4981  \n\nCoefficients:\n                 Estimate Std. Error z value Pr(>|z|)  \n(Intercept)       -0.7282     0.3254  -2.238   0.0252 *\nageclassjuvenile   0.1335     0.4504   0.296   0.7669  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 112.93  on 87  degrees of freedom\nResidual deviance: 112.84  on 86  degrees of freedom\n  (15 observations deleted due to missingness)\nAIC: 116.84\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n:::\n\n\nFor Bernoulli data like this, however, over-dispersion is not an issue\n[@molenberghs2012]. Forbinomial and Poisson data, this should be\napproximately. We can note the impact of given factors using *Anova*\n\n\n::: {.cell}\n\n```{.r .cell-code}\nAnova(as_glm, type=\"III\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type III tests)\n\nResponse: movement\n         LR Chisq Df Pr(>Chisq)\nageclass 0.087974  1     0.7668\n```\n:::\n:::\n\n\nwhich now uses likelihood-based tests by default. Similarly, the\n*summary* output notes details related to fitting the model (Number of\nFisher scoring iterations). To interpret the coefficient from the glm,\nwe need to consider the link function (here, the logit). If we\nbacktransform the logit link function, we can actually say that\njuveniles had a $e^\\beta$ greater odds of movement than adults, which is\nequal to\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexp(.1335)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.142821\n```\n:::\n:::\n\n\nand very close to 1 (thus the high p-value given our small sample size).\n\nWhile this example simply replicates the $\\chi^2$ tests we learned\nearlier (deviations may arise when counts are low or high for any group,\nand thus $\\hat{p}$ approaches extreme values and breaks the\nassumptions!), the power of these models comes from the ability to\nconsider *multiple* variables (which we couldn't do before). These\nmodels are sometimes called log-linear models.\n\nTo consider this approach and extend glm to binomial data, consider work\nby @bueno2020. The authors carried out a series of experiments to\ndetermine how various factors impacted colonization of a host algae,\n*Sargassum filipendula*, by a small amphipod, *Cymadusa filosa*.\n\n[![Rob Young, Centre for Biodiversity Genomics - CC - BY - NC -\nS](/images/Cymadusa_filosa.jpg)](https://molecol-unesp-clp.jimdofree.com/2017/03/01/the-first-set-of-microsatellite-markers-for-the-amphipod-cymadusa-filosa/)\n\nFor one experiment, they stocked portions of aquariums with pieces of\nalgal. Half the algae pieces had adult amphipods present(4 total; the\nspecies builds tubes to live on algae) while the other half had no adult\nresidents. Juveniles were initially placed on patches of natural\nsubstrate, artificial substrate, or bare areas(no substrate) in the\naquarium. After 24 hours, the number of juveniles that colonized the\nfocal algae were counted. Since the number of introduced juveniles was\nknown, the number that did not colonize was also accounted for (raw data\nestimated from supplemental data given variation in sample size).\n\n\n::: {.cell}\n\n```{.r .cell-code}\njuvenile <- read.csv (\"data/Supplemental_Data_Bueno_2020-S1-Presence of adults_lab.csv\", \n                      stringsAsFactors = T)\n```\n:::\n\n\nsince the *adults* column indicates the presence or absence of adults,\nlet's update it for clarity\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(plyr)\njuvenile$adults_updated <- factor(revalue(as.character(juvenile$adults), c(\"0\"= \"absent\", \"4\" =\"present\")))\n```\n:::\n\n\nThis is an example of a factorial-design with the following hypotheses:\n\n-   null hypothesis\n    -   H~O~: There is no impact on the habitat type juveniles start in\n        on their likelihood to move\n    -   H~O~: There is no impact on adult presence in the new habitat on\n        the likelihood of juveniles to move\n    -   H~O~: There is no interaction between the impacts of the habitat\n        type juveniles start in and adult presence in the new habitat on\n        the likelihood of juveniles to move\n-   alternative hypothesis\n    -   H~A~: There is an impact on the habitat type juveniles start in\n        on their likelihood to move\n    -   H~A~: There is an impact on adult presence in the new habitat on\n        the likelihood of juveniles to move\n    -   H~A~: There is an interaction between the impacts of the habitat\n        type juveniles start in and adult presence in the new habitat on\n        the likelihood of juveniles to move\n\nThe outcome, however, is a proportion. Note we *can* fit a linear model\nto the data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\njuvenile_fit_lm <- lm(Colonized ~ adults_updated*source.habitat, \n    juvenile)\nplot(juvenile_fit_lm)\n```\n\n::: {.cell-output-display}\n![](Linear_model_extensions_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](Linear_model_extensions_files/figure-html/unnamed-chunk-24-2.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](Linear_model_extensions_files/figure-html/unnamed-chunk-24-3.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](Linear_model_extensions_files/figure-html/unnamed-chunk-24-4.png){width=672}\n:::\n:::\n\n\nThe assumptions don't even look that bad, but note the data is\nover-dispersed (will come back to this). We also know the model will\nmake predictions that aren't logical (outcomes outside of the 0-1\nrange). For this reason we will use a generalized linear model (or a log\nlinear model) to analyze the data. We can fit a glm using the binomial\nfamily.\n\n\n::: {.cell}\n\n```{.r .cell-code}\njuvenile_fit_glm <- glm(cbind(Colonized, Not_colonized) ~ adults*source.habitat, \n    juvenile, family = \"binomial\")\n```\n:::\n\n\nThe summary again allows us to estimate the dispersion parameter by\ndividing the residual deviance by its associated degrees of freedom, and\nwe can now consider the impact of multiple variables (including\ninteractions, which are significant here!).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(juvenile_fit_glm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = cbind(Colonized, Not_colonized) ~ adults * source.habitat, \n    family = \"binomial\", data = juvenile)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-3.5767  -0.8964   0.3554   1.3298   3.5784  \n\nCoefficients:\n                             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                   1.84583    0.31063   5.942 2.81e-09 ***\nadults                       -0.28417    0.09507  -2.989 0.002799 ** \nsource.habitatnatural        -3.88271    0.43669  -8.891  < 2e-16 ***\nsource.habitatnone            1.02207    0.55484   1.842 0.065459 .  \nadults:source.habitatnatural  0.46383    0.13819   3.356 0.000789 ***\nadults:source.habitatnone    -0.38722    0.15665  -2.472 0.013441 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 347.435  on 35  degrees of freedom\nResidual deviance:  97.393  on 30  degrees of freedom\nAIC: 186.64\n\nNumber of Fisher Scoring iterations: 5\n```\n:::\n\n```{.r .cell-code}\nAnova(juvenile_fit_glm, type=\"III\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type III tests)\n\nResponse: cbind(Colonized, Not_colonized)\n                      LR Chisq Df Pr(>Chisq)    \nadults                   9.712  1   0.001831 ** \nsource.habitat         195.748  2  < 2.2e-16 ***\nadults:source.habitat   34.738  2  2.862e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nWe see that there is a significant interaction between the presence of\nadults and source habitat on the proportion of amphipods that move to\ncolonize algae.\n\nADD RESULTS...break up one way anova, etc.\n\nHowever, we also note that our dispersion estimate is 97.393/30 \\~ 3;\nthis should be closer to 1! What should we do? One option is to use an\napproach that estimates the dispersion parameter. Though not fully\ndeveloped here, this approach uses a \"quasi-binomial\" family.\n\n\n::: {.cell}\n\n```{.r .cell-code}\njuvenile_fit_glm_quasi <- glm(cbind(Colonized, Not_colonized) ~ adults*source.habitat, \n    juvenile, family = \"quasibinomial\")\nsummary(juvenile_fit_glm_quasi)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = cbind(Colonized, Not_colonized) ~ adults * source.habitat, \n    family = \"quasibinomial\", data = juvenile)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-3.5767  -0.8964   0.3554   1.3298   3.5784  \n\nCoefficients:\n                             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                    1.8458     0.5562   3.319  0.00238 ** \nadults                        -0.2842     0.1702  -1.669  0.10544    \nsource.habitatnatural         -3.8827     0.7819  -4.966 2.56e-05 ***\nsource.habitatnone             1.0221     0.9934   1.029  0.31177    \nadults:source.habitatnatural   0.4638     0.2474   1.875  0.07060 .  \nadults:source.habitatnone     -0.3872     0.2805  -1.381  0.17760    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for quasibinomial family taken to be 3.205612)\n\n    Null deviance: 347.435  on 35  degrees of freedom\nResidual deviance:  97.393  on 30  degrees of freedom\nAIC: NA\n\nNumber of Fisher Scoring iterations: 5\n```\n:::\n\n```{.r .cell-code}\nAnova(juvenile_fit_glm_quasi, type=\"III\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type III tests)\n\nResponse: cbind(Colonized, Not_colonized)\n                      LR Chisq Df Pr(>Chisq)    \nadults                   3.030  1   0.081751 .  \nsource.habitat          61.064  2  5.496e-14 ***\nadults:source.habitat   10.837  2   0.004435 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\ndd in McFadden's R\\^2.rcompanion:compareglm\n\n#### Beta regression\n\nBeta regression focuses on true proportion data where the outcome is\nbetween 0 and 1.\n\n#### Poisson regression\n\nPoisson regression focuses on count-based data.\n\n#### Non-linear options\n\n## Data are not independent\n\n### In respect to predictors\n\nA major issue for linear models is when predictors are co-linear.\nMathematically speaking, perfect collinearity occurs when any column of\nthe design (*X*) matrix can be derived by combining other columns.\nPerfect collinearity will lead to a message noting singularity issues,\nwhich is R's way of telling you the matrix isn't invertible (which it\nhas to be to solve the equation).\n\nEven partial collinearity will lead to an increase in Type II errors\n[@zuur2010]. To put it simply, partitioning variance among related\npredictors is hard. For this reason, a few approaches may be used.\n\n#### Check for issues\n\nThe first step is identifying issues. From the outset, relationships\namong predictor variables can be assessed using the *pairs* function in\nR. If two variables are highly correlated (r^2^ \\> .8 is a general\nlimit), only one should be included in the model. Similarly, variance\ninflation factors (vif) can be assessed for the final and other models\nto consider this issues (all this is covered in the [previous chapter\nthat introduces multiple\nregression](Combining_numerical_and_categorical_predictors.qmd){target=\"_blank\"}.\n\n### In respect to measured outcomes\n\nWhen outcome variables are linked together, a few options exist. Note\nthis issue may be obvious from checks of assumptions, but it also may be\ndue to experimental design.\n\nConsider this example. In order to investigate impacts of climate stress\non oysters, specimens are placed in individual tanks and held at normal\nsummer (calculated using recent data) temperature or at temperatures\npredicted under 2 IPCC --- Intergovernmental Panel on Climate Change-\nscenarios. Oysters were also exposed to predator cues by dropping in\nwater from tanks with 0, low (.25/m2), or high (2/m2) predators. After\ntwo months changes in oyster shell length (growth) was measured.\nTwenty-five oysters were measured for each treatment combination.\n\nYou hopefully recognize this as a factorial ANOVA experiment that you\nknow how to analyze. If you need a reminder, see the [chapter on ANOVA\nextensions](../chapters/More_ANOVAs.qmd){target=\"_blank\"}. Experiments\nlike this are odd, however, given the space they require. It is far more\ncommon to put lots of organisms in a single container given space and\ncosts. However, this means our measurements are connected; remember\n[blocking and paired\ntests](../chapters/More_ANOVAs.qmd){target=\"_blank\"})?\n\nThere are several ways to deal with this. Here we explore each for our\noyster example.\n\n\n::: {.cell}\n\n:::\n\n\n#### Ignore it (don't do this!)\n\nFirst, let's ignore the lack of independence. This is *not* an option,\nbut it let's you see the impact.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngrowth_lm <- lm(growth~predator_cue*temperature, experiment)\nplot(growth_lm)\n```\n\n::: {.cell-output-display}\n![](Linear_model_extensions_files/figure-html/unnamed-chunk-29-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](Linear_model_extensions_files/figure-html/unnamed-chunk-29-2.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](Linear_model_extensions_files/figure-html/unnamed-chunk-29-3.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](Linear_model_extensions_files/figure-html/unnamed-chunk-29-4.png){width=672}\n:::\n\n```{.r .cell-code}\nlibrary(car)\nAnova(growth_lm, type=\"III\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnova Table (Type III tests)\n\nResponse: growth\n                          Sum Sq  Df F value    Pr(>F)    \n(Intercept)               15.576   1 16.3673 7.265e-05 ***\npredator_cue              22.085   2 11.6031 1.635e-05 ***\ntemperature               70.061   2 36.8090 1.753e-14 ***\npredator_cue:temperature  21.376   4  5.6154 0.0002558 ***\nResiduals                205.563 216                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nWe find significant main effects and interactions using this *wrong*\napproach.\n\n#### Find average for each unit\n\nOne way of doing this focuses on the average for each unit\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(Rmisc)\naveraged_experiment <- summarySE(experiment, measurevar = \"growth\",\n                             groupvars = c(\"predator_cue\", \"temperature\", \"container\"))\nlibrary(rmarkdown)\npaged_table(averaged_experiment)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"predator_cue\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"temperature\"],\"name\":[2],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"container\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"N\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"growth\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"sd\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"se\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"ci\"],\"name\":[8],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"high\",\"2\":\"ambient\",\"3\":\"c\",\"4\":\"25\",\"5\":\"0.7893411\",\"6\":\"0.7859693\",\"7\":\"0.1571939\",\"8\":\"0.3244322\"},{\"1\":\"high\",\"2\":\"elevated_scenario1\",\"3\":\"f\",\"4\":\"25\",\"5\":\"0.8200710\",\"6\":\"0.6938491\",\"7\":\"0.1387698\",\"8\":\"0.2864068\"},{\"1\":\"high\",\"2\":\"elevated_scenario2\",\"3\":\"i\",\"4\":\"25\",\"5\":\"2.8548160\",\"6\":\"1.0748246\",\"7\":\"0.2149649\",\"8\":\"0.4436658\"},{\"1\":\"none\",\"2\":\"ambient\",\"3\":\"a\",\"4\":\"25\",\"5\":\"2.0791580\",\"6\":\"0.7758511\",\"7\":\"0.1551702\",\"8\":\"0.3202556\"},{\"1\":\"none\",\"2\":\"elevated_scenario1\",\"3\":\"d\",\"4\":\"25\",\"5\":\"2.5724463\",\"6\":\"1.0918574\",\"7\":\"0.2183715\",\"8\":\"0.4506966\"},{\"1\":\"none\",\"2\":\"elevated_scenario2\",\"3\":\"g\",\"4\":\"25\",\"5\":\"2.9199695\",\"6\":\"1.1043899\",\"7\":\"0.2208780\",\"8\":\"0.4558697\"},{\"1\":\"normal\",\"2\":\"ambient\",\"3\":\"b\",\"4\":\"25\",\"5\":\"1.7124232\",\"6\":\"1.1511870\",\"7\":\"0.2302374\",\"8\":\"0.4751867\"},{\"1\":\"normal\",\"2\":\"elevated_scenario1\",\"3\":\"e\",\"4\":\"25\",\"5\":\"1.4993876\",\"6\":\"0.9759186\",\"7\":\"0.1951837\",\"8\":\"0.4028394\"},{\"1\":\"normal\",\"2\":\"elevated_scenario2\",\"3\":\"h\",\"4\":\"25\",\"5\":\"3.1388696\",\"6\":\"1.0096012\",\"7\":\"0.2019202\",\"8\":\"0.4167429\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nand use that for your analysis.\n\n\n::: {.cell}\n\n```{.r .cell-code}\naverage_analysis <- lm(growth~predator_cue*temperature, averaged_experiment)\nAnova(average_analysis, type = \"III\")\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in Anova.lm(average_analysis, type = \"III\"): residual df = 0\n```\n:::\n:::\n\n\nbut that leads to an issue! Since we only get 9 average outcomes and our\nmodel requires 10 degrees of freedom (consider why), we are left with no\n\"noise\" to make the denominator for our F ratio! Even when this doesn't\nhappen, you have reduced your data to a much smaller number of points\nand are not getting credit for all your work! This is a good example of\nwhy you should analyze simulated data before you run an experiment, but\nthere are other options.\n\n#####Blocking\n\nThe blocking approach we've already covered works might seem appropriate\nhere.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nblocking_analysis <- lm(growth~predator_cue*temperature+container, experiment)\nAnova(blocking_analysis, type = \"III\")\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in Anova.III.lm(mod, error, singular.ok = singular.ok, ...): there are aliased coefficients in the model\n```\n:::\n:::\n\n\nbut its not? Why? This error means now our model matrix has collinearity\nissues. WE can actually see where\n\n\n::: {.cell}\n\n```{.r .cell-code}\nalias(blocking_analysis)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel :\ngrowth ~ predator_cue * temperature + container\n\nComplete :\n                                                 (Intercept) predator_cuenone\ncontainerf                                        0           0              \ncontainerg                                       -1           1              \ncontainerh                                        0           0              \ncontaineri                                        1          -1              \npredator_cuenone:temperatureelevated_scenario1    0           0              \npredator_cuenormal:temperatureelevated_scenario1  0           0              \npredator_cuenone:temperatureelevated_scenario2   -1           1              \npredator_cuenormal:temperatureelevated_scenario2  0           0              \n                                                 predator_cuenormal\ncontainerf                                        0                \ncontainerg                                        0                \ncontainerh                                        1                \ncontaineri                                       -1                \npredator_cuenone:temperatureelevated_scenario1    0                \npredator_cuenormal:temperatureelevated_scenario1  0                \npredator_cuenone:temperatureelevated_scenario2    0                \npredator_cuenormal:temperatureelevated_scenario2  1                \n                                                 temperatureelevated_scenario1\ncontainerf                                        1                           \ncontainerg                                        1                           \ncontainerh                                        0                           \ncontaineri                                       -1                           \npredator_cuenone:temperatureelevated_scenario1    0                           \npredator_cuenormal:temperatureelevated_scenario1  0                           \npredator_cuenone:temperatureelevated_scenario2    1                           \npredator_cuenormal:temperatureelevated_scenario2  0                           \n                                                 temperatureelevated_scenario2\ncontainerf                                        0                           \ncontainerg                                        1                           \ncontainerh                                        0                           \ncontaineri                                        0                           \npredator_cuenone:temperatureelevated_scenario1    0                           \npredator_cuenormal:temperatureelevated_scenario1  0                           \npredator_cuenone:temperatureelevated_scenario2    1                           \npredator_cuenormal:temperatureelevated_scenario2  0                           \n                                                 containerb containerc\ncontainerf                                        0          0        \ncontainerg                                        1          1        \ncontainerh                                       -1          0        \ncontaineri                                        0         -1        \npredator_cuenone:temperatureelevated_scenario1    0          0        \npredator_cuenormal:temperatureelevated_scenario1  0          0        \npredator_cuenone:temperatureelevated_scenario2    1          1        \npredator_cuenormal:temperatureelevated_scenario2 -1          0        \n                                                 containerd containere\ncontainerf                                       -1         -1        \ncontainerg                                       -1          0        \ncontainerh                                        0         -1        \ncontaineri                                        1          1        \npredator_cuenone:temperatureelevated_scenario1    1          0        \npredator_cuenormal:temperatureelevated_scenario1  0          1        \npredator_cuenone:temperatureelevated_scenario2   -1          0        \npredator_cuenormal:temperatureelevated_scenario2  0         -1        \n```\n:::\n:::\n\n\nthough the output is confusing. In general, the issue here is each unit\nonly contributes to one level of other traits..so if we know the average\nimpact of ambient temperatures, for example, and the impacts in two of\nthe treatments that were held at that temperature, we can predict the\nother. If instead each unit contributed to multiple levels, like in\n[feather experiment](../chapters/More_ANOVAs.qmd){target=\"blank\"}) this\nisn't an issue.\n\n#### Random effects\n\nOur final option takes a new approach. It considers the units we\nmeasured as simply a sample from a larger population. Using that\nbackground, we use the information from the units to consider the\ndistribution of sample effects we might see. The impact of unit is then\nconsidered a random-effect. For this to work, you probably want 5+\nlevels of the unit variable. This is because we are using the means to\nestimate variance (confusing?). For factors with \\<5 levels, random\neffects likely offer no benefit [@gomes2022].\n\nWhen models contain fixed (what we've done before) and random effects,\nwe call them mixed-effects models. Two common packages for carrying out\nthis analysis in R are the **nlme** and **lme4** packages. We will focus\non the lme4 package here. Random effects can be entered in the *lmer*\n(linear mixed-effects regression) function and specified as (1\\|Grouping\nUnit). One nice thing about **lme4** is it will handle crossed and\nrandom effects on it's own **as long as you don't repeat unit names**.\nFor example, we could note\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4)\nmixed_analysis <- lmer(growth~predator_cue*temperature+(1|container), experiment)\n```\n:::\n\n\nOnce built, we need to consider assumptions. The main assumption we add\nhere is that the random effects are normally distributed. This should be\nchecked at each level of grouping. The *check_mixed_model* function\n(provided below) offers an automated approach for one level (also known\nas one-way random effects).\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_mixed_model <- function (model, model_name = NULL) {\n  #collection of things you might check for mixed model\n  par(mfrow = c(2,3))\n  if(length(names(ranef(model))<2)){\n    qqnorm(ranef(model, drop = T)[[1]], pch = 19, las = 1, cex = 1.4, main= paste(model_name, \n                                                                                  \"\\n Random effects Q-Q plot\"))\n    qqline(ranef(model, drop = T)[[1]])\n  }\n  plot(fitted(model),residuals(model), main = paste(model_name, \n                                                    \"\\n residuals vs fitted\"))\n  qqnorm(residuals(model), main =paste(model_name, \n                                       \"\\nresiduals q-q plot\"))\n  qqline(residuals(model))\n  hist(residuals(model), main = paste(model_name, \n                                      \"\\nresidual histogram\"))\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_mixed_model(mixed_analysis)\n```\n\n::: {.cell-output-display}\n![](Linear_model_extensions_files/figure-html/unnamed-chunk-36-1.png){width=672}\n:::\n:::\n\n\nHere we have only 9 levels of units, so the spread is not perfect.\nHowever, we also know each of these is itself an average,and averages\nshould be normally-distributed under the central limith theorem, so we\ncan plow ahead.\n\nWe can consider the outcome using our *summary* command - note the\noutput denotes we have 225 observations and 9 grouping levels.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(mixed_analysis)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: growth ~ predator_cue * temperature + (1 | container)\n   Data: experiment\n\nREML criterion at convergence: 631.3\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.68605 -0.79915 -0.02646  0.70023  2.72393 \n\nRandom effects:\n Groups    Name        Variance Std.Dev.\n container (Intercept) 4.6171   2.1487  \n Residual              0.9517   0.9755  \nNumber of obs: 225, groups:  container, 9\n\nFixed effects:\n                                                 Estimate Std. Error t value\n(Intercept)                                       0.78934    2.15758   0.366\npredator_cuenone                                  1.28982    3.05129   0.423\npredator_cuenormal                                0.92308    3.05129   0.303\ntemperatureelevated_scenario1                     0.03073    3.05129   0.010\ntemperatureelevated_scenario2                     2.06547    3.05129   0.677\npredator_cuenone:temperatureelevated_scenario1    0.46256    4.31517   0.107\npredator_cuenormal:temperatureelevated_scenario1 -0.24377    4.31517  -0.056\npredator_cuenone:temperatureelevated_scenario2   -1.22466    4.31517  -0.284\npredator_cuenormal:temperatureelevated_scenario2 -0.63903    4.31517  -0.148\n\nCorrelation of Fixed Effects:\n             (Intr) prdtr_cnn prdtr_cnr tmpr_1 tmpr_2 prdtr_cnn:_1 prdtr_cnr:_1\npredatr_cnn  -0.707                                                            \nprdtr_cnrml  -0.707  0.500                                                     \ntmprtrlvt_1  -0.707  0.500     0.500                                           \ntmprtrlvt_2  -0.707  0.500     0.500     0.500                                 \nprdtr_cnn:_1  0.500 -0.707    -0.354    -0.707 -0.354                          \nprdtr_cnr:_1  0.500 -0.354    -0.707    -0.707 -0.354  0.500                   \nprdtr_cnn:_2  0.500 -0.707    -0.354    -0.354 -0.707  0.500        0.250      \nprdtr_cnr:_2  0.500 -0.354    -0.707    -0.354 -0.707  0.250        0.500      \n             prdtr_cnn:_2\npredatr_cnn              \nprdtr_cnrml              \ntmprtrlvt_1              \ntmprtrlvt_2              \nprdtr_cnn:_1             \nprdtr_cnr:_1             \nprdtr_cnn:_2             \nprdtr_cnr:_2  0.500      \n```\n:::\n:::\n\n\nWe can also still use *Anova* to get p-values. However, these are now\ncalculated by default using likelihood-associated $\\chi^2$ tests.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nAnova(mixed_analysis, type = \"III\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type III Wald chisquare tests)\n\nResponse: growth\n                          Chisq Df Pr(>Chisq)\n(Intercept)              0.1338  1     0.7145\npredator_cue             0.1898  2     0.9095\ntemperature              0.6020  2     0.7401\npredator_cue:temperature 0.1837  4     0.9960\n```\n:::\n:::\n\n\nYou can also ask for F tests, but note the degrees of freedom associated\nwith these tests is not clear. It's somewhere between the \"average\" and\n\"ignore\" approach used above.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nAnova(mixed_analysis, type = \"III\", test=\"F\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type III Wald F tests with Kenward-Roger df)\n\nResponse: growth\n                              F Df  Df.res Pr(>F)\n(Intercept)              0.1338  1 3230137 0.7145\npredator_cue             0.0949  2 3230137 0.9095\ntemperature              0.3010  2 3230137 0.7401\npredator_cue:temperature 0.0459  4 3230137 0.9960\n```\n:::\n:::\n\n\nNote this approach suggests we do not have enough data to reject the\nnull hypothesis. Ignoring the linkages among data led to *very*\ndifferent results. This issue (pseudopreplication) has been noted in\necology and other fields [@hurlbert1984; @heffner1996; @lazic2010].\n\n## Errors are not equal among groups\n\nAnother option is to use weighted-least squares regression - this\napproach specifically helps when residuals are not evenly distributed\namong groups (or when a funnel/cone appears when you plot the model to\ncheck assumptions). For example, we could take the sdm_model (just as an\nexample of use! it's not needed here!) This approach assume you built\nthe model and then noted an issue with heteroscedasticity. If so, we can\ncalculate a weight for each residual that is based on its variance.\nDoing this requires an iterative process similar to those used for\nestimation for generalized linear modes. - below makes a value that\nincreases with low variance.\n\n`{r} wt_sdm <- 1 / lm(abs(sdm_model$residuals) ~ sdm_model$fitted.values)$fitted.values^2}`\n\nWe can then add a new argument to the *lm* function to use these\nweights.\n\n`{r} sdm_model_wls <-lm(Standing.Dead..dry..m2.~Snail.Level * Nitrogen.level, valdez_2023[valdez_2023$Snail.Level != \"uncaged\",], weights = wt_sdm)}`\n\nWe can then continue on our normal route:\n\n`{r} plot(sdm_model_wls) Anova(sdm_model_wls, type=\"III\")}`\n\nIf you compare the two models you notice slight differences - these are\nminimal here due to lack of differences in variance.\n\n`{r} summary(sdm_model) summary(sdm_model_wls)}`\n\nWhy not just always do this? Because weighted least squares implicitly\nassumes we *know* the weights. We are actually estimating them, so small\ndatasets may lead to bad estimates and outcomes.\n\n## Residuals are not normally distributed\n\nA very common concern regarding linear models is normality. I list it\nfirst here due to how often I see it noted, but in fact this assumption\nis one of the least important (and the assumption is based on residuals,\nnot data!). However, non-normal residuals are often (not always)\nconnected to other issues, namely linearity, as noted above.\n\n## Combinining these\n\n## Next steps\n\nThese methods can be extended to other models that are used when linear\nmodel assumptions are not met, which is the focus of the next chapter.\n",
    "supporting": [
      "Linear_model_extensions_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\r\n<script src=\"../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}